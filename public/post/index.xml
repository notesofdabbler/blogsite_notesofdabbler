<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Notes of a Dabbler</title>
    <link>/post/</link>
    <description>Recent content in Posts on Notes of a Dabbler</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 26 Apr 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Proofs without Words using gganimate</title>
      <link>/2020/04/26/proofnowords/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/04/26/proofnowords/</guid>
      <description>&lt;p&gt;I recently watched the 2 part workshop (&lt;a href=&#34;https://www.youtube.com/watch?v=h29g21z0a68&#34;&gt;part 1&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=0m4yywqNPVY&#34;&gt;part 2&lt;/a&gt;) on ggplot2 and extensions given by &lt;a href=&#34;https://www.data-imaginist.com/about&#34;&gt;Thomas Lin Pedersen&lt;/a&gt;. First of, it was really nice of Thomas to give the close to 4 hour workshop for the benefit of the community. I personally learnt a lot from it. I wanted to try out &lt;a href=&#34;https://gganimate.com/index.html&#34;&gt;gganimate&lt;/a&gt; extension that was covered during the workshop.&lt;/p&gt;
&lt;p&gt;There are several resources on the web that show animations/illustrations of proofs of mathematical identities and theorems without words (or close to it). I wanted to take a few of those examples and use gganimate to recreate the illustration. While this exercise may not qualify anywhere close to “useful” or “productive”, it was definitely a super “fun” way for me to try out gganimate.&lt;/p&gt;
&lt;div id=&#34;example-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 1:&lt;/h2&gt;
&lt;p&gt;This example is taken from &lt;a href=&#34;https://artofproblemsolving.com/wiki/index.php/Proofs_without_words&#34;&gt;AoPS Online&lt;/a&gt; and the result is that sum of first &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; odd numbers equals &lt;span class=&#34;math inline&#34;&gt;\(n^2\)&lt;/span&gt;. &lt;span class=&#34;math display&#34;&gt;\[ 1 + 3 + 5 + \ldots + (2n - 1) = n^2 \]&lt;/span&gt; The animated version of the proof is show below (&lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/sum_of_odds.R&#34;&gt;R code&lt;/a&gt;, &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/sum_of_odds.html&#34;&gt;html file&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/learn_gganimate/master/proof_without_words/figures/sum_of_odds.gif&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 2:&lt;/h2&gt;
&lt;p&gt;This example is also taken from &lt;a href=&#34;https://artofproblemsolving.com/wiki/index.php/Proofs_without_words&#34;&gt;AoPS Online&lt;/a&gt; and the result is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ 1^3 + 2^3 + \ldots + (n-1)^3 + n^3 = (1 + 2 + \ldots + n)^2 \]&lt;/span&gt; The animated version of the proof is shown below ( &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/sum_of_cubes.R&#34;&gt;R code&lt;/a&gt;, &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/sum_of_cubes.html&#34;&gt;html file&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/learn_gganimate/master/proof_without_words/figures/sum_of_cubes.gif&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 3&lt;/h2&gt;
&lt;p&gt;This example from &lt;a href=&#34;https://artofproblemsolving.com/wiki/index.php/Proofs_without_words&#34;&gt;AoPS Online&lt;/a&gt; illustrates the result&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{1}{2^2} + \frac{1}{2^4} + \frac{1}{2^6} + \frac{1}{2^8} + \ldots = \frac{1}{3} \]&lt;/span&gt; The animated version of the proof is shown below ( &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/infinite_series_1.R&#34;&gt;R code&lt;/a&gt;, &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/infinite_series_1.html&#34;&gt;html file&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/learn_gganimate/master/proof_without_words/figures/infinite_series_1.gif&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-4&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 4&lt;/h2&gt;
&lt;p&gt;According to Pythagoras theorem, &lt;span class=&#34;math display&#34;&gt;\[ a^2 + b^2 = c^2 \]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; are sides of a right angled triangle (with &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; being the side opposite &lt;span class=&#34;math inline&#34;&gt;\(90^o\)&lt;/span&gt; angle)&lt;/p&gt;
&lt;p&gt;There was an illustration of the proof of pythogoras theorem in a &lt;a href=&#34;https://www.youtube.com/watch?v=T2K11eFepcs&#34;&gt;video&lt;/a&gt; from &lt;a href=&#34;http://www.eChalk.co.uk&#34;&gt;echalk&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The animated version of the proof is shown below ( &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/pythagoras_theorem.R&#34;&gt;R code&lt;/a&gt;, &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/pythagoras_theorem.html&#34;&gt;html file&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/learn_gganimate/master/proof_without_words/figures/pythagoras_theorem.gif&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;In summary, it was great to use gganimate for these animations since it does all the magic with making transitions work nicely.&lt;/p&gt;
&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
&lt;script&gt;
(function() {
var d = document, s = d.createElement(&#39;script&#39;);
s.src = &#39;https://notesofdabbler.disqus.com/embed.js&#39;;
s.setAttribute(&#39;data-timestamp&#39;, +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;https://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Keeping up with Tidyverse Functions using Tidy Tuesday Screencasts</title>
      <link>/2019/08/06/tidyscreencastfuncs/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/08/06/tidyscreencastfuncs/</guid>
      <description>&lt;p&gt;David Robinson has done several &lt;a href=&#34;https://www.youtube.com/channel/UCeiiqmVK07qhY-wvg3IZiZQ&#34;&gt;screencasts&lt;/a&gt; where he analyzes a Tidy Tuesday dataset live. I have listened to a few of them and found them very interesting and instructive. As I don’t use R on a daily basis, I have not kept up with what the latest is in Tidyverse. So when I listened to his screencasts, I learnt functions that I was not aware of. Since I sometimes forget which function I learnt, I wanted to extract all the functions used in the screencasts so that it is easier for me to refer to the ones that I am not aware of but should learn.&lt;/p&gt;
&lt;p&gt;The approach I took is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get all the Rmd analysis files from the screencast github repo.&lt;/li&gt;
&lt;li&gt;Extract the list of libraries and functions used in each .Rmd file&lt;/li&gt;
&lt;li&gt;Plot frequencies of function use and review functions that I am not aware of&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The html file with all the code and results is in this &lt;a href=&#34;http://notesofdabbler.github.io/blog_notesofdabbler/getCodeFuncs.html&#34;&gt;location&lt;/a&gt;. The R file used to generate the html file is &lt;a href=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/getCodeFuncs.R&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The plot below shows the how many analyses used a particular package. &lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/figure/libcntplt-1.png&#34; width=&#34;800&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The top library as tidyverse is to be expected. It is interesting that lubridate is second. I can see that broom is used quite a bit since after exploratory analysis in the screencast, David explores some models. There are several packages that I was not aware of but I will probably look up the following: widyr, fuzzyjoin, glue, janitor, patchwork and the context in which they were used in the screencast.&lt;/p&gt;
&lt;p&gt;The plot below shows the number of functions used from each package. &lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/figure/pkgcntplt-1.png&#34; width=&#34;800&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, most used functions are from &lt;em&gt;ggplot2&lt;/em&gt;, &lt;em&gt;dplyr&lt;/em&gt;, &lt;em&gt;tidyr&lt;/em&gt; since there is lot of exploratory analysis and visualization of data in the screencasts.&lt;/p&gt;
&lt;p&gt;The next series of plots shows the individual functions used from the packages.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/figure/fncountplt-1.png&#34; width=&#34;800&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/figure/fncountplt-2.png&#34; width=&#34;800&#34; /&gt; &lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/figure/fncountplt-3.png&#34; width=&#34;800&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Based on the above figures, I am listing below some functions that I was not aware of and should learn&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;count&lt;/em&gt; function in &lt;em&gt;dplyr&lt;/em&gt; as a easier way to count for each group or sum a variable for each group.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;geom_col&lt;/em&gt; function in &lt;em&gt;ggplot2&lt;/em&gt; for bar graphs&lt;/li&gt;
&lt;li&gt;I became aware of &lt;em&gt;forcats&lt;/em&gt; package for working with factors. &lt;em&gt;fct_reorder&lt;/em&gt; and &lt;em&gt;fct_lump&lt;/em&gt; from the package were used frequently.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;tidyr&lt;/em&gt; functions - &lt;em&gt;nest/unnest&lt;/em&gt;, &lt;em&gt;crossing&lt;/em&gt;, &lt;em&gt;separate_rows&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;I realized that I know only a few functions in &lt;em&gt;stringr&lt;/em&gt; and should learn more about several functions that were used in the screencast.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
&lt;script&gt;
(function() {
var d = document, s = d.createElement(&#39;script&#39;);
s.src = &#39;https://notesofdabbler.disqus.com/embed.js&#39;;
s.setAttribute(&#39;data-timestamp&#39;, +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;https://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

</description>
    </item>
    
    <item>
      <title>Fastai Collaborative Filtering with R and Reticulate</title>
      <link>/2018/04/01/fastaicollabfilterr/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/01/fastaicollabfilterr/</guid>
      <description>&lt;p&gt;Jeremy Howard and Rachel Thomas are founders of &lt;a href=&#34;http://www.fast.ai/&#34;&gt;fast.ai&lt;/a&gt; whose aim is to make deep learning accessible to all. They offer a course called &lt;a href=&#34;http://course.fast.ai/&#34;&gt;Practical Deep Learning for Coders (Part 1)&lt;/a&gt;. The last session, taught by Jeremy, was in Fall 2017 and the videos were released early January 2018. Their approach is top down by showing different applications first as black boxes followed by progressive peeling of the black box to teach the details of how things work. The course uses python and they have developed a python library &lt;a href=&#34;https://github.com/fastai/fastai/tree/master/fastai&#34;&gt;fastai&lt;/a&gt; that is a wrapper around &lt;a href=&#34;http://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I wanted to learn reticulate by trying to create a R version of one of the python notebooks from that class. The class covers the topic of collaborative filtering in &lt;a href=&#34;http://course.fast.ai/lessons/lesson5.html&#34;&gt;lecture 5&lt;/a&gt; and &lt;a href=&#34;http://course.fast.ai/lessons/lesson6.html&#34;&gt;lecture 6&lt;/a&gt;. The dataset used is a sample of &lt;a href=&#34;http://files.grouplens.org/datasets/movielens/ml-latest-small.zip&#34;&gt;movielens dataset&lt;/a&gt; where about ~670 users have rated ~9000 movies. The objective is to develop a model to predict the rating that a user will give for a particular movie.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb&#34;&gt;Jupyter notebook&lt;/a&gt; for this topic is divided into 2 portions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the first half, the model is developed using just high level fastai functions. The R notebook for the first half is located &lt;a href=&#34;https://notesofdabbler.github.io/fastai_dl1_withR/movieLens.nb.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In the second half, the model is developed from scratch and 3 different types of models are discussed going from matrix factorization type model to deep learning type models. The R notebook for the second half is located &lt;a href=&#34;https://notesofdabbler.github.io/fastai_dl1_withR/movieLens_from_Scratch.nb.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since the first half involved mainly python functions from fastai library, it seemed like a good use case for reticulate since we could use reticulate just for model development and use R functions for other pre and post processing tasks. The second half involved model building from scratch. In pyTorch, custom models need to be written as python classes. While it was still possible to use reticulate in this case, this may not be the ideal use case since it might be better for somebody developing custom models to do the whole work in python. But once they wrap it into a python package, it is easier to use from R. Overall, reticulate was great to work with and it made it very easy to translate a python function to an equivalent R function. It is a great addition to the R packages.&lt;/p&gt;
&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
&lt;script&gt;
(function() {
var d = document, s = d.createElement(&#39;script&#39;);
s.src = &#39;https://notesofdabbler.disqus.com/embed.js&#39;;
s.setAttribute(&#39;data-timestamp&#39;, +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;https://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

</description>
    </item>
    
    <item>
      <title>Exploring Instacart Dataset with PCA</title>
      <link>/2017/05/22/exploreinstacart/</link>
      <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/22/exploreinstacart/</guid>
      <description>&lt;p&gt;Recently, &lt;a href=&#34;https://www.instacart.com/&#34;&gt;Instacart&lt;/a&gt; released a &lt;a href=&#34;https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2&#34;&gt;dataset&lt;/a&gt; of ~3 million orders made by ~200,000 users at different days of week and times of day. There is also an ongoing &lt;a href=&#34;https://www.kaggle.com/c/instacart-market-basket-analysis&#34;&gt;Kaggle competition&lt;/a&gt; to predict which products a user will buy again. My goal here is more modest where I just wanted to explore the dataset to find patterns of purchasing behaviour by hour of day, day of week and number of days prior to current order. An &lt;a href=&#34;https://cdn-images-1.medium.com/max/800/1*wKfV6OV-_1Ipwrl7AjjSuw.png&#34;&gt;example&lt;/a&gt; of this kind of analysis is also shown in their blog. Here I wanted to explore if I can find such kind of patters by using the very common and popular dimension reduction technique - Principal Component Analysis (PCA). There are several great resources that introduce PCA if you are not familiar with PCA. One of the resources is the set of &lt;a href=&#34;https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/&#34;&gt;video lectures&lt;/a&gt; on machine learning by Prof. Hastie and Prof. Tibshirani.&lt;/p&gt;
&lt;p&gt;The general approach that I have followed is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do principal component analysis on the data (each row is a product, each column is a time period (hour of day, day of week or number of days prior to current order))&lt;/li&gt;
&lt;li&gt;Review the loading plots of first two principal components to see purchase patterns&lt;/li&gt;
&lt;li&gt;Identify top 20 products that have high scores in either first or the second principal component&lt;/li&gt;
&lt;li&gt;Check the purchasing pattern by checking the average number of orders for the products that were identified as having top scores in one of the principal components.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Spoiler Alert&lt;/strong&gt;: Since my analysis is basic, don’t be disappointed if there are no big Aha moments (there will be none). But I think it is still fun to see how we can extract such information directly from data.&lt;/p&gt;
&lt;p&gt;I downloaded the data from the following &lt;a href=&#34;https://www.instacart.com/datasets/grocery-shopping-2017&#34;&gt;link&lt;/a&gt;. The data dictionary is in the following &lt;a href=&#34;https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b&#34;&gt;link&lt;/a&gt;. The full code with results is in the following &lt;a href=&#34;http://notesofdabbler.github.io/blog_notesofdabbler/exploreData_PCA.html&#34;&gt;location&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Below are some basic info on the datasets&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The number of users are ~200,000.&lt;/li&gt;
&lt;li&gt;The number of orders are ~3.4M. The number of products are ~50K or which ~5K account for 80% of total orders&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;pca-to-find-patterns-of-purchase-by-hour-of-day&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;PCA to find patterns of purchase by hour of day&lt;/h2&gt;
&lt;p&gt;The goal here is to find products with different patterns of purchase timing by hour of day with PCA. Dataset for PCA has for each product (rows), the percentage of product orders at each hour of day (column). Since all the data is in percentages, I didn’t do any further scaling of data.&lt;/p&gt;
&lt;p&gt;The plot of cumulative variance shows that first component accounts for 44% of variance, first two account for 58% and first 3 account for 67% of variance.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/exploreInstacart/master/figure/unnamed-chunk-9-1.png&#34; width=&#34;600&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Next, we will look at the first two loadings since first 2 components account for 58% of variance.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/exploreInstacart/master/figure/unnamed-chunk-10-1.png&#34; width=&#34;600&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;First principal component loading PC1 indicates a pattern of either higher percentage of purcahses in the morning or evening. The second principal component loading indicates a pattern where there is higher purchase around 11am and 4pm. To check which product items follow these patterns, we look at products that either have high scores or low scores on a principal component. So here we take the top 20 and bottom 20 products in terms of their scores on PC1. The actual pattern still may not quite match the loading plot since the overall pattern is a combination of all principal component loadings.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/exploreInstacart/master/figure/unnamed-chunk-11-1.png&#34; width=&#34;600&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Below is the table that lists the actual products that are in top and bottom scores of PC1. Ice cream purchases tend to occur more in the evening. Items like granola bars, krispie treats, apples are purchased more in the morning.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/exploreInstacart/master/figure/top_bottom_20_products_PC1scores.png&#34; width=&#34;600&#34; /&gt;

&lt;/div&gt;
&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
&lt;script&gt;
(function() {
var d = document, s = d.createElement(&#39;script&#39;);
s.src = &#39;https://notesofdabbler.disqus.com/embed.js&#39;;
s.setAttribute(&#39;data-timestamp&#39;, +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;https://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>My First Blogdown Post</title>
      <link>/2017/05/15/myfirstblogdownpost/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/15/myfirstblogdownpost/</guid>
      <description>&lt;p&gt;Since I have been hearing a lot about virtues of &lt;a href=&#34;https://github.com/rstudio/blogdown&#34;&gt;Blogdown&lt;/a&gt; in various forums, I thought I will also give it a shot. I am planning to do my future blog posts in blogdown. I used to have my &lt;a href=&#34;http://notesofdabbler.wordpress.com&#34;&gt;older site&lt;/a&gt; in Wordpress. But I don’t have plans at least in the near term to migrate the older content.&lt;/p&gt;
&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
&lt;script&gt;
(function() {
var d = document, s = d.createElement(&#39;script&#39;);
s.src = &#39;https://notesofdabbler.disqus.com/embed.js&#39;;
s.setAttribute(&#39;data-timestamp&#39;, +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;https://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

</description>
    </item>
    
  </channel>
</rss>