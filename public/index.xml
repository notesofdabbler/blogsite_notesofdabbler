<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes of a Dabbler</title>
    <link>/</link>
    <description>Recent content on Notes of a Dabbler</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Jul 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Using Pyomo from R through the magic of Reticulate</title>
      <link>/2020/07/01/rpyomo/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/07/01/rpyomo/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.pyomo.org/&#34;&gt;Pyomo&lt;/a&gt; is a python based open-source package for modeling optimization problems. It makes it easy to represent optimization problems and can send it to different solvers (both open-source and commercial) to solve the problem and return the results in python. The advantage of pyomo compared to commercial software such as &lt;a href=&#34;https://www.gams.com/&#34;&gt;GAMS&lt;/a&gt; and &lt;a href=&#34;https://ampl.com/&#34;&gt;AMPL&lt;/a&gt; is the ability to code using standard python syntax (with some modifications for pyomo constructs). Another open source package for modeling optimization problems is &lt;a href=&#34;https://jump.dev/JuMP.jl/v0.19.0/index.html&#34;&gt;JuMP&lt;/a&gt; in Julia language.&lt;/p&gt;
&lt;p&gt;My goal in this blog is to see how far I can get in terms of using Pyomo from R using the &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34;&gt;reticulate&lt;/a&gt; package. The simplest option would be to develop the model in pyomo and call it from R using reticulate. However, it still requires writing the pyomo model in python. I want to use reticulate to write the pyomo model using R. In this blog post, I describe two examples in detail where I developed the pyomo model in R and discuss my learnings. I first discuss set-up in terms of packages needed followed by discussion of the two examples.&lt;/p&gt;
&lt;div id=&#34;set-up&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Set-up&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load libraries
library(reticulate)
library(dplyr)
library(tidyr)
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For using pyomo package through reticulate, it is necessary to have python and pyomo already installed. We can import pyomo as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Import pyomo
pyo = import(&amp;quot;pyomo.environ&amp;quot;, convert = FALSE)
bi = import_builtins()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When trying different examples, I saw some issues when not using the &lt;code&gt;convert = FALSE&lt;/code&gt; option and so started using this option when importing pyomo.&lt;/p&gt;
&lt;p&gt;I also ran into some signal handling errors when using pyomo solvers. I added the following two commands to turn off signal handling (based on this &lt;a href=&#34;https://github.com/PyUtilib/pyutilib/issues/31&#34;&gt;thread&lt;/a&gt;). It seems to have worked but I don’t know yet if it has other side effects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pyulib = import(&amp;quot;pyutilib.subprocess.GlobalData&amp;quot;)
pyulib$DEFINE_SIGNAL_HANDLERS_DEFAULT = FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-1-rosenbrock-problem-unconstrained-nonlinear-optimization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example 1: Rosenbrock Problem (Unconstrained Nonlinear Optimization)&lt;/h3&gt;
&lt;p&gt;The first example is a unconstrained nonlinear minimization of &lt;a href=&#34;https://en.wikipedia.org/wiki/Rosenbrock_function&#34;&gt;rosenbrock function&lt;/a&gt;
&lt;span class=&#34;math display&#34;&gt;\[
\min \;\; (x - 1)^2 + 100(y - x^2)^2
\]&lt;/span&gt;
Since arithmetic operators in pyomo are overloaded to generate pyomo expressions, I wrote functions for &lt;a href=&#34;https://github.com/notesofdabbler/R_pyomo/blob/master/operators.R&#34;&gt;arithmetic operators&lt;/a&gt; based on this &lt;a href=&#34;https://github.com/rstudio/reticulate/issues/170&#34;&gt;discussion thread&lt;/a&gt; and sourced them here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;quot;operators.R&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pyomo model using python for this problem is in this &lt;a href=&#34;https://github.com/notesofdabbler/R_pyomo/blob/master/python_codes/rosen.ipynb&#34;&gt;location&lt;/a&gt;. Reticulate makes it easy to write code close to what it is in python (with certain modifications)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create model object
M = pyo$ConcreteModel()

# Define and initialize the variables*
M$x = pyo$Var(initialize = 1.5)
M$y = pyo$Var(initialize = 1.5)

# Define the objective function
M$obj = pyo$Objective(expr = (1 - M$x)**2 + 100 * (M$y - M$x**2)**2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can check the model that has been created with the &lt;code&gt;pprint&lt;/code&gt; command. While the R command &lt;code&gt;M$pprint()&lt;/code&gt; works and shows output in the console, I couldn’t get it to show in the R markdown output. So I am using the python chunk to show the output.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;r.M.pprint()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 2 Var Declarations
##     x : Size=1, Index=None
##         Key  : Lower : Value : Upper : Fixed : Stale : Domain
##         None :  None :   1.5 :  None : False : False :  Reals
##     y : Size=1, Index=None
##         Key  : Lower : Value : Upper : Fixed : Stale : Domain
##         None :  None :   1.5 :  None : False : False :  Reals
## 
## 1 Objective Declarations
##     obj : Size=1, Index=None, Active=True
##         Key  : Active : Sense    : Expression
##         None :   True : minimize : (1.0 - x)**2.0 + 100.0*(y - x**2.0)**2.0
## 
## 3 Declarations: x y obj&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pyomo can interface with different open-source and commercial solvers depending on the type of optimization problem. Since this is a nonlinear problem, we use the open-source solver &lt;a href=&#34;https://github.com/coin-or/Ipopt&#34;&gt;IPOPT&lt;/a&gt; to solve the problem. Usually solvers have to be separately installed to be used with pyomo.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;solver = pyo$SolverFactory(&amp;quot;ipopt&amp;quot;)
res = solver$solve(M, logfile = &amp;#39;tmp.log&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since the console output from solver doesn’t show in R markdown output, I wrote it to a temporary file and read it back again.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x = paste(readLines(&amp;quot;tmp.log&amp;quot;, encoding = &amp;quot;UTF-8&amp;quot;))
writeLines(x[2:63]) # lines 1 and 64 cause encoding issues in blog rendering&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Ipopt 3.12.12: 
## 
## ******************************************************************************
## This program contains Ipopt, a library for large-scale nonlinear optimization.
##  Ipopt is released as open source code under the Eclipse Public License (EPL).
##          For more information visit http://projects.coin-or.org/Ipopt
## ******************************************************************************
## 
## This is Ipopt version 3.12.12, running with linear solver mumps.
## NOTE: Other linear solvers might be more efficient (see Ipopt documentation).
## 
## Number of nonzeros in equality constraint Jacobian...:        0
## Number of nonzeros in inequality constraint Jacobian.:        0
## Number of nonzeros in Lagrangian Hessian.............:        3
## 
## Total number of variables............................:        2
##                      variables with only lower bounds:        0
##                 variables with lower and upper bounds:        0
##                      variables with only upper bounds:        0
## Total number of equality constraints.................:        0
## Total number of inequality constraints...............:        0
##         inequality constraints with only lower bounds:        0
##    inequality constraints with lower and upper bounds:        0
##         inequality constraints with only upper bounds:        0
## 
## iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
##    0  5.6500000e+01 0.00e+00 1.00e+02  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
##    1  2.4669972e-01 0.00e+00 2.22e-01  -1.0 7.40e-01    -  1.00e+00 1.00e+00f  1
##    2  1.6256267e-01 0.00e+00 2.04e+00  -1.7 1.48e+00    -  1.00e+00 2.50e-01f  3
##    3  8.6119444e-02 0.00e+00 1.08e+00  -1.7 2.36e-01    -  1.00e+00 1.00e+00f  1
##    4  4.3223836e-02 0.00e+00 1.23e+00  -1.7 2.61e-01    -  1.00e+00 1.00e+00f  1
##    5  1.5610508e-02 0.00e+00 3.54e-01  -1.7 1.18e-01    -  1.00e+00 1.00e+00f  1
##    6  5.3544798e-03 0.00e+00 5.51e-01  -1.7 1.67e-01    -  1.00e+00 1.00e+00f  1
##    7  6.1281576e-04 0.00e+00 5.19e-02  -1.7 3.87e-02    -  1.00e+00 1.00e+00f  1
##    8  2.8893076e-05 0.00e+00 4.52e-02  -2.5 4.53e-02    -  1.00e+00 1.00e+00f  1
##    9  3.4591761e-08 0.00e+00 3.80e-04  -2.5 3.18e-03    -  1.00e+00 1.00e+00f  1
## iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
##   10  1.2680803e-13 0.00e+00 3.02e-06  -5.7 3.62e-04    -  1.00e+00 1.00e+00f  1
##   11  7.0136460e-25 0.00e+00 1.72e-12  -8.6 2.13e-07    -  1.00e+00 1.00e+00f  1
## 
## Number of Iterations....: 11
## 
##                                    (scaled)                 (unscaled)
## Objective...............:   1.5551321399859192e-25    7.0136459513364959e-25
## Dual infeasibility......:   1.7239720368203862e-12    7.7751138860599418e-12
## Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
## Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
## Overall NLP error.......:   1.7239720368203862e-12    7.7751138860599418e-12
## 
## 
## Number of objective function evaluations             = 18
## Number of objective gradient evaluations             = 12
## Number of equality constraint evaluations            = 0
## Number of inequality constraint evaluations          = 0
## Number of equality constraint Jacobian evaluations   = 0
## Number of inequality constraint Jacobian evaluations = 0
## Number of Lagrangian Hessian evaluations             = 11
## Total CPU secs in IPOPT (w/o function evaluations)   =      0.037
## Total CPU secs in NLP function evaluations           =      0.000
## 
## EXIT: Optimal Solution Found.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The solution of the model can be access using the defined variables of the model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Display model solution
M$x(); M$y()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 1.0000000000008233&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 1.0000000000016314&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2-transportation-problem-linear-programming&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example 2: Transportation Problem (Linear Programming)&lt;/h3&gt;
&lt;p&gt;Given a set of markets with demands and plants that can supply the demands, the goal in the transportation problem is to determine minimum cost shipping scenario that meets market demands while satisfying supply capacity of plants. The python pyomo version of this example is in this &lt;a href=&#34;https://nbviewer.jupyter.org/github/Pyomo/PyomoGallery/blob/master/transport/transport.ipynb&#34;&gt;location&lt;/a&gt;. The decision variables and parameters of the problem are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Decision Variable: &lt;span class=&#34;math inline&#34;&gt;\(x_{ij}\)&lt;/span&gt; - quantity shipped from plant &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; to market &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Parameters:
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt; - number of plants, &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; - number of markets&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(c_{ij}\)&lt;/span&gt; - cost of shipping per unit from plant &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; to market &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Cap_i\)&lt;/span&gt; - capacity of plant &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Dem_j\)&lt;/span&gt; - demand in market &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The mathematical formulation of the problem is:
&lt;span class=&#34;math display&#34;&gt;\[
\mbox{(Minimize Cost)}\;\;\min \;\; \sum_{i=1}^P\sum_{j=1}^Mc_{ij}x_{ij}  \\
\mbox{(Supply from a plant below capacity)} \;\;\sum_{j=1}^Mx_{ij} \leq Cap_i, \;\; i=1,2,\ldots,P \\
\mbox{(Supply to a market meets demand)}\;\;\sum_{i=1}^Px_{ij} \geq Dem_j, \;\; j=1,2,\ldots,M \\
\mbox{(shipments are non-negative)}\;\;x_{ij}\geq 0, \;\; i=1,2,\ldots,P, \;\; j=1,2,\ldots,M
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Cost is a dictionary where keys are tuples of the form (plant, market). I couldn’t figure out how to specify a R list that would translate to such a dictionary in python. So I used a round about way by converting a tibble to a pandas dataframe to a dictionary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# shipping cost between plants and markets
costdf = tribble(
  ~plants, ~mkts, ~dtab,
  &amp;quot;seattle&amp;quot;, &amp;quot;new-york&amp;quot;, 2.5,
  &amp;quot;seattle&amp;quot;, &amp;quot;chicago&amp;quot;, 1.7,
  &amp;quot;seattle&amp;quot;, &amp;quot;topeka&amp;quot;, 1.8,
  &amp;quot;san-diego&amp;quot;, &amp;quot;new-york&amp;quot;, 2.5,
  &amp;quot;san-diego&amp;quot;, &amp;quot;chicago&amp;quot;, 1.8,
  &amp;quot;san-diego&amp;quot;, &amp;quot;topeka&amp;quot;, 1.4
)

costdf = costdf %&amp;gt;% mutate(cost = dtab * 90)

dict_from_df = function(df) {
  names(df) = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;, &amp;quot;z&amp;quot;)
  dfpy = r_to_py(df)$set_index(c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;))
  dfdict = dfpy$to_dict()[&amp;quot;z&amp;quot;]
  return(dfdict)
}

cost = dict_from_df(costdf %&amp;gt;% select(plants, mkts, cost))
cost&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## {(&amp;#39;seattle&amp;#39;, &amp;#39;new-york&amp;#39;): 225.0, (&amp;#39;seattle&amp;#39;, &amp;#39;chicago&amp;#39;): 153.0, (&amp;#39;seattle&amp;#39;, &amp;#39;topeka&amp;#39;): 162.0, (&amp;#39;san-diego&amp;#39;, &amp;#39;new-york&amp;#39;): 225.0, (&amp;#39;san-diego&amp;#39;, &amp;#39;chicago&amp;#39;): 162.0, (&amp;#39;san-diego&amp;#39;, &amp;#39;topeka&amp;#39;): 125.99999999999999}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we create a model object and define the parameters and decision variables&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create the model object
M = pyo$ConcreteModel()

# set the model parameters
M$plants = pyo$Set(initialize = c(&amp;quot;seattle&amp;quot;, &amp;quot;san-diego&amp;quot;))
M$mkts = pyo$Set(initialize = c(&amp;quot;new-york&amp;quot;, &amp;quot;chicago&amp;quot;, &amp;quot;topeka&amp;quot;))

M$cap = pyo$Param(M$plants, initialize = list(&amp;quot;seattle&amp;quot; = 350, &amp;quot;san-diego&amp;quot; = 600))
M$dem = pyo$Param(M$mkts, initialize = list(&amp;quot;new-york&amp;quot; = 325, &amp;quot;chicago&amp;quot; = 300, &amp;quot;topeka&amp;quot; = 275))
M$cost = pyo$Param(M$plants, M$mkts, initialize = cost)

# define the model decision variables (shipment quantities between a plant and market)
# bounds specify that x&amp;gt;=0
M$x = pyo$Var(M$plants, M$mkts, bounds = tuple(0, NULL))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we will set the constraint on supply from plants being below their capacities. In pyomo, the constraints can be described with a function that describes the rule to construct the constraint. In python pyomo, the supply constraint will be listed as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def supply_rule(m, i):
    expr = sum(m.x[i, j] for j in mkts) &amp;lt;= cap[i]
    return expr
M.supply_cons = pyo.Constraint(plants, rule = supply_rule)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function &lt;code&gt;supply_rule&lt;/code&gt; is a function that tells what the constraint expression is for a particular plant &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;. Then &lt;code&gt;M.supply_cons&lt;/code&gt; line ensures that the constraint is generated for each of the plants. Python shines here since this is represented succintly using list comprehensions. Since I am not sure how to do an equivalent representation using R, I used loops in the function to construct the constraint. I also wasn’t sure if using R function to represent the rule will work when passing the R function to create the supply constraint. But it worked fine and I guess that’s the magic of reticulate. Below is the supply constraint constructed in R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# supply from plant &amp;lt;= plant capacity
supply_rule = function(m, i) {
  supply = 0
  for (j in bi$list(m$mkts)) {
    supply = supply + m$x[tuple(i, j)]
  }
  expr = supply &amp;lt;= m$cap[[i]]
  return(expr)
}
M$supply_cons = pyo$Constraint(M$plants, rule = supply_rule)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can check if the supply constraint is constructed correctly&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;r.M.supply_cons.pprint()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## supply_cons : Size=2, Index=plants, Active=True
##     Key       : Lower : Body                                                               : Upper : Active
##     san-diego :  -Inf : x[san-diego,new-york] + x[san-diego,chicago] + x[san-diego,topeka] : 600.0 :   True
##       seattle :  -Inf :       x[seattle,new-york] + x[seattle,chicago] + x[seattle,topeka] : 350.0 :   True&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similarly, we can construct the demand constraint&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# supply to a market meets its demand
demand_rule = function(m, j) {
  demand = 0
  for (i in bi$list(m$plants)) {
    demand = demand + m$x[tuple(i, j)]
  }
  expr = demand &amp;gt;= m$dem[[j]]
  return(expr)
}
M$demand_cons = pyo$Constraint(M$mkts, rule = demand_rule)  &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;r.M.demand_cons.pprint()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## demand_cons : Size=3, Index=mkts, Active=True
##     Key      : Lower : Body                                        : Upper : Active
##      chicago : 300.0 :   x[seattle,chicago] + x[san-diego,chicago] :  +Inf :   True
##     new-york : 325.0 : x[seattle,new-york] + x[san-diego,new-york] :  +Inf :   True
##       topeka : 275.0 :     x[seattle,topeka] + x[san-diego,topeka] :  +Inf :   True&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we construct the objective of total shipment cost and set it to be minimized.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# objective to minimize shipping cost
objective_rule = function(m) {
  totcost = 0
  for (i in bi$list(m$plants)) {
    for (j in bi$list(m$mkts)) {
      totcost = totcost + m$cost[tuple(i, j)] * m$x[tuple(i, j)]
    }
  }
  return(totcost)
}
M$objective = pyo$Objective(rule = objective_rule, sense = pyo$minimize)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since this a linear program, we use the open-source solver &lt;a href=&#34;https://www.gnu.org/software/glpk/&#34;&gt;glpk&lt;/a&gt; to solve this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# solve using solver glpk
opt = pyo$SolverFactory(&amp;#39;glpk&amp;#39;)
results = opt$solve(M, logfile = &amp;quot;tmp.log&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Optimal shipping cost based on solving this problem is:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;r.M.objective()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 153675.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we display the shipment quantities. It is a bit more verbose since we worked with the option of &lt;code&gt;convert = FALSE&lt;/code&gt; resulting in explicitly extracting desired values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res_L = list()
k = 1
for(i in bi$list(M$plants)) {
    for(j in bi$list(M$mkts)) {
        res_L[[k]] = list(plant = i, mkt = j, qty = py_to_r(M$x[tuple(i, j)]()))
        k = k + 1
  }
}
res_df = bind_rows(res_L)
res_df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   plant     mkt        qty
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 seattle   new-york     0
## 2 seattle   chicago    300
## 3 seattle   topeka       0
## 4 san-diego new-york   325
## 5 san-diego chicago      0
## 6 san-diego topeka     275&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;a-few-more-examples&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A Few More Examples&lt;/h3&gt;
&lt;p&gt;There are 3 more examples where I developed the pyomo model in R. I have listed them below along with location of the code.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Single machine scheduling problem (&lt;a href=&#34;https://notesofdabbler.github.io/R_pyomo/machine_scheduling.html&#34;&gt;R code&lt;/a&gt;): This &lt;a href=&#34;https://nbviewer.jupyter.org/github/jckantor/ND-Pyomo-Cookbook/blob/master/notebooks/04.01-Machine-Bottleneck.ipynb&#34;&gt;example&lt;/a&gt; is taken from Jeffrey Kantor’s &lt;a href=&#34;https://jckantor.github.io/ND-Pyomo-Cookbook/&#34;&gt;pyomo cookbook&lt;/a&gt; gallery. The goal here is to schedule a set of jobs which have a certain release date, due date and duration on a machine to minimize total delays. This is a mixed-integer linear program and the pyomo modeling uses the disjunction construct from the &lt;a href=&#34;https://pyomo.readthedocs.io/en/stable/modeling_extensions/gdp.html&#34;&gt;GDP&lt;/a&gt; module to specify constraints that two jobs do not overlap in the machine at the same time.&lt;/li&gt;
&lt;li&gt;Optimal control (&lt;a href=&#34;https://notesofdabbler.github.io/R_pyomo/optimal_control.html&#34;&gt;R code&lt;/a&gt;): Pyomo has a &lt;a href=&#34;https://pyomo.readthedocs.io/en/stable/modeling_extensions/dae.html&#34;&gt;DAE (Differential-Algebraic Equation)&lt;/a&gt; module that makes it easy to specifiy dynamic optimization and control problems. The optimal control &lt;a href=&#34;https://github.com/Pyomo/pyomo/blob/master/examples/dae/Optimal_Control.py&#34;&gt;example&lt;/a&gt; from pyomo repo is coded using R in this example.&lt;/li&gt;
&lt;li&gt;Kinetics Paramter Estimation (&lt;a href=&#34;https://notesofdabbler.github.io/R_pyomo/parameter_estimation.html&#34;&gt;R Code&lt;/a&gt;): An example of parameter estimation for a reaction system is coded in this location. This example is from the book &lt;a href=&#34;https://sites.engineering.ucsb.edu/~jbraw/chemreacfun/&#34;&gt;Chemical Reactor Design and Analysis&lt;/a&gt; by Rawlings and Ekerdt.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;summary&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;p&gt;Here I covered two examples to show how to develop a pyomo model from R using the reticulate package. While it might still be easier to develop the pyomo model in python (since it was meant to be that way), I found that it is possible to develop pyomo models in R also fairly easily albeit with some modifications (some maybe less elegant compred to the python counterpart). It may still be better to develop more involved pyomo models in python but reticulate offers a way to develop simple to intermediate levels models directly in R. I am summarizing key learnings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Need to overload arithmetic operators to enable things like addition etc. between pyomo objects&lt;/li&gt;
&lt;li&gt;Use the option &lt;code&gt;convert = FALSE&lt;/code&gt; to retain pyomo objects as python objects potentially avoid issues that are hard to troubleshoot.&lt;/li&gt;
&lt;li&gt;Lack of list comprehension in R makes some of the constraint specifications more verbose but still works.&lt;/li&gt;
&lt;li&gt;Need to be careful about indexing (sometimes need to explicitly specify a tuple and sometimes not)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Proofs without Words using gganimate</title>
      <link>/2020/04/26/proofnowords/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/04/26/proofnowords/</guid>
      <description>&lt;p&gt;I recently watched the 2 part workshop (&lt;a href=&#34;https://www.youtube.com/watch?v=h29g21z0a68&#34;&gt;part 1&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=0m4yywqNPVY&#34;&gt;part 2&lt;/a&gt;) on ggplot2 and extensions given by &lt;a href=&#34;https://www.data-imaginist.com/about&#34;&gt;Thomas Lin Pedersen&lt;/a&gt;. First of, it was really nice of Thomas to give the close to 4 hour workshop for the benefit of the community. I personally learnt a lot from it. I wanted to try out &lt;a href=&#34;https://gganimate.com/index.html&#34;&gt;gganimate&lt;/a&gt; extension that was covered during the workshop.&lt;/p&gt;
&lt;p&gt;There are several resources on the web that show animations/illustrations of proofs of mathematical identities and theorems without words (or close to it). I wanted to take a few of those examples and use gganimate to recreate the illustration. This was a fun way for me to try out gganimate.&lt;/p&gt;
&lt;div id=&#34;example-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 1:&lt;/h2&gt;
&lt;p&gt;This example is taken from &lt;a href=&#34;https://artofproblemsolving.com/wiki/index.php/Proofs_without_words&#34;&gt;AoPS Online&lt;/a&gt; and the result is that sum of first &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; odd numbers equals &lt;span class=&#34;math inline&#34;&gt;\(n^2\)&lt;/span&gt;. &lt;span class=&#34;math display&#34;&gt;\[ 1 + 3 + 5 + \ldots + (2n - 1) = n^2 \]&lt;/span&gt; The gganimate version of the proof (using the method in &lt;a href=&#34;https://artofproblemsolving.com/wiki/index.php/Proofs_without_words&#34;&gt;AoPS Online&lt;/a&gt;) is shown below (&lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/sum_of_odds.R&#34;&gt;R code&lt;/a&gt;, &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/sum_of_odds.html&#34;&gt;html file&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/learn_gganimate/master/proof_without_words/figures/sum_of_odds.gif&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 2:&lt;/h2&gt;
&lt;p&gt;This example is also taken from &lt;a href=&#34;https://artofproblemsolving.com/wiki/index.php/Proofs_without_words&#34;&gt;AoPS Online&lt;/a&gt; and the result is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ 1^3 + 2^3 + \ldots + (n-1)^3 + n^3 = (1 + 2 + \ldots + n)^2 \]&lt;/span&gt; The gganimate version of the proof (using the method in &lt;a href=&#34;https://artofproblemsolving.com/wiki/index.php/Proofs_without_words&#34;&gt;AoPS Online&lt;/a&gt;) is shown below ( &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/sum_of_cubes.R&#34;&gt;R code&lt;/a&gt;, &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/sum_of_cubes.html&#34;&gt;html file&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/learn_gganimate/master/proof_without_words/figures/sum_of_cubes.gif&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 3&lt;/h2&gt;
&lt;p&gt;This example from &lt;a href=&#34;https://artofproblemsolving.com/wiki/index.php/Proofs_without_words&#34;&gt;AoPS Online&lt;/a&gt; illustrates the result&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{1}{2^2} + \frac{1}{2^4} + \frac{1}{2^6} + \frac{1}{2^8} + \ldots = \frac{1}{3} \]&lt;/span&gt; The gganimate version of the proof (using the method in &lt;a href=&#34;https://artofproblemsolving.com/wiki/index.php/Proofs_without_words&#34;&gt;AoPS Online&lt;/a&gt;) is shown below ( &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/infinite_series_1.R&#34;&gt;R code&lt;/a&gt;, &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/infinite_series_1.html&#34;&gt;html file&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/learn_gganimate/master/proof_without_words/figures/infinite_series_1.gif&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-4&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 4&lt;/h2&gt;
&lt;p&gt;According to Pythagoras theorem, &lt;span class=&#34;math display&#34;&gt;\[ a^2 + b^2 = c^2 \]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; are sides of a right angled triangle (with &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; being the side opposite &lt;span class=&#34;math inline&#34;&gt;\(90^o\)&lt;/span&gt; angle)&lt;/p&gt;
&lt;p&gt;There was an illustration of the proof of pythogoras theorem in a &lt;a href=&#34;https://www.youtube.com/watch?v=T2K11eFepcs&#34;&gt;video&lt;/a&gt; from &lt;a href=&#34;http://www.eChalk.co.uk&#34;&gt;echalk&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The gganimate version of the proof is shown below ( &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/pythagoras_theorem.R&#34;&gt;R code&lt;/a&gt;, &lt;a href=&#34;https://github.com/notesofdabbler/learn_gganimate/blob/master/proof_without_words/pythagoras_theorem.html&#34;&gt;html file&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/learn_gganimate/master/proof_without_words/figures/pythagoras_theorem.gif&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;In summary, it was great to use gganimate for these animations since it does all the magic with making transitions work nicely.&lt;/p&gt;
&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
&lt;script&gt;
(function() {
var d = document, s = d.createElement(&#39;script&#39;);
s.src = &#39;https://notesofdabbler.disqus.com/embed.js&#39;;
s.setAttribute(&#39;data-timestamp&#39;, +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;https://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Keeping up with Tidyverse Functions using Tidy Tuesday Screencasts</title>
      <link>/2019/08/06/tidyscreencastfuncs/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/08/06/tidyscreencastfuncs/</guid>
      <description>&lt;p&gt;David Robinson has done several &lt;a href=&#34;https://www.youtube.com/channel/UCeiiqmVK07qhY-wvg3IZiZQ&#34;&gt;screencasts&lt;/a&gt; where he analyzes a Tidy Tuesday dataset live. I have listened to a few of them and found them very interesting and instructive. As I don’t use R on a daily basis, I have not kept up with what the latest is in Tidyverse. So when I listened to his screencasts, I learnt functions that I was not aware of. Since I sometimes forget which function I learnt, I wanted to extract all the functions used in the screencasts so that it is easier for me to refer to the ones that I am not aware of but should learn.&lt;/p&gt;
&lt;p&gt;The approach I took is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get all the Rmd analysis files from the screencast github repo.&lt;/li&gt;
&lt;li&gt;Extract the list of libraries and functions used in each .Rmd file&lt;/li&gt;
&lt;li&gt;Plot frequencies of function use and review functions that I am not aware of&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The html file with all the code and results is in this &lt;a href=&#34;http://notesofdabbler.github.io/blog_notesofdabbler/getCodeFuncs.html&#34;&gt;location&lt;/a&gt;. The R file used to generate the html file is &lt;a href=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/getCodeFuncs.R&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The plot below shows the how many analyses used a particular package. &lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/figure/libcntplt-1.png&#34; width=&#34;800&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The top library as tidyverse is to be expected. It is interesting that lubridate is second. I can see that broom is used quite a bit since after exploratory analysis in the screencast, David explores some models. There are several packages that I was not aware of but I will probably look up the following: widyr, fuzzyjoin, glue, janitor, patchwork and the context in which they were used in the screencast.&lt;/p&gt;
&lt;p&gt;The plot below shows the number of functions used from each package. &lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/figure/pkgcntplt-1.png&#34; width=&#34;800&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, most used functions are from &lt;em&gt;ggplot2&lt;/em&gt;, &lt;em&gt;dplyr&lt;/em&gt;, &lt;em&gt;tidyr&lt;/em&gt; since there is lot of exploratory analysis and visualization of data in the screencasts.&lt;/p&gt;
&lt;p&gt;The next series of plots shows the individual functions used from the packages.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/figure/fncountplt-1.png&#34; width=&#34;800&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/figure/fncountplt-2.png&#34; width=&#34;800&#34; /&gt; &lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/blog_notesofdabbler/master/popularTidyVerseFuncs/figure/fncountplt-3.png&#34; width=&#34;800&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Based on the above figures, I am listing below some functions that I was not aware of and should learn&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;count&lt;/em&gt; function in &lt;em&gt;dplyr&lt;/em&gt; as a easier way to count for each group or sum a variable for each group.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;geom_col&lt;/em&gt; function in &lt;em&gt;ggplot2&lt;/em&gt; for bar graphs&lt;/li&gt;
&lt;li&gt;I became aware of &lt;em&gt;forcats&lt;/em&gt; package for working with factors. &lt;em&gt;fct_reorder&lt;/em&gt; and &lt;em&gt;fct_lump&lt;/em&gt; from the package were used frequently.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;tidyr&lt;/em&gt; functions - &lt;em&gt;nest/unnest&lt;/em&gt;, &lt;em&gt;crossing&lt;/em&gt;, &lt;em&gt;separate_rows&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;I realized that I know only a few functions in &lt;em&gt;stringr&lt;/em&gt; and should learn more about several functions that were used in the screencast.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
&lt;script&gt;
(function() {
var d = document, s = d.createElement(&#39;script&#39;);
s.src = &#39;https://notesofdabbler.disqus.com/embed.js&#39;;
s.setAttribute(&#39;data-timestamp&#39;, +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;https://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

</description>
    </item>
    
    <item>
      <title>Fastai Collaborative Filtering with R and Reticulate</title>
      <link>/2018/04/01/fastaicollabfilterr/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/01/fastaicollabfilterr/</guid>
      <description>&lt;p&gt;Jeremy Howard and Rachel Thomas are founders of &lt;a href=&#34;http://www.fast.ai/&#34;&gt;fast.ai&lt;/a&gt; whose aim is to make deep learning accessible to all. They offer a course called &lt;a href=&#34;http://course.fast.ai/&#34;&gt;Practical Deep Learning for Coders (Part 1)&lt;/a&gt;. The last session, taught by Jeremy, was in Fall 2017 and the videos were released early January 2018. Their approach is top down by showing different applications first as black boxes followed by progressive peeling of the black box to teach the details of how things work. The course uses python and they have developed a python library &lt;a href=&#34;https://github.com/fastai/fastai/tree/master/fastai&#34;&gt;fastai&lt;/a&gt; that is a wrapper around &lt;a href=&#34;http://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I wanted to learn reticulate by trying to create a R version of one of the python notebooks from that class. The class covers the topic of collaborative filtering in &lt;a href=&#34;http://course.fast.ai/lessons/lesson5.html&#34;&gt;lecture 5&lt;/a&gt; and &lt;a href=&#34;http://course.fast.ai/lessons/lesson6.html&#34;&gt;lecture 6&lt;/a&gt;. The dataset used is a sample of &lt;a href=&#34;http://files.grouplens.org/datasets/movielens/ml-latest-small.zip&#34;&gt;movielens dataset&lt;/a&gt; where about ~670 users have rated ~9000 movies. The objective is to develop a model to predict the rating that a user will give for a particular movie.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb&#34;&gt;Jupyter notebook&lt;/a&gt; for this topic is divided into 2 portions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the first half, the model is developed using just high level fastai functions. The R notebook for the first half is located &lt;a href=&#34;https://notesofdabbler.github.io/fastai_dl1_withR/movieLens.nb.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In the second half, the model is developed from scratch and 3 different types of models are discussed going from matrix factorization type model to deep learning type models. The R notebook for the second half is located &lt;a href=&#34;https://notesofdabbler.github.io/fastai_dl1_withR/movieLens_from_Scratch.nb.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since the first half involved mainly python functions from fastai library, it seemed like a good use case for reticulate since we could use reticulate just for model development and use R functions for other pre and post processing tasks. The second half involved model building from scratch. In pyTorch, custom models need to be written as python classes. While it was still possible to use reticulate in this case, this may not be the ideal use case since it might be better for somebody developing custom models to do the whole work in python. But once they wrap it into a python package, it is easier to use from R. Overall, reticulate was great to work with and it made it very easy to translate a python function to an equivalent R function. It is a great addition to the R packages.&lt;/p&gt;
&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
&lt;script&gt;
(function() {
var d = document, s = d.createElement(&#39;script&#39;);
s.src = &#39;https://notesofdabbler.disqus.com/embed.js&#39;;
s.setAttribute(&#39;data-timestamp&#39;, +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;https://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

</description>
    </item>
    
    <item>
      <title>Exploring Instacart Dataset with PCA</title>
      <link>/2017/05/22/exploreinstacart/</link>
      <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/22/exploreinstacart/</guid>
      <description>&lt;p&gt;Recently, &lt;a href=&#34;https://www.instacart.com/&#34;&gt;Instacart&lt;/a&gt; released a &lt;a href=&#34;https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2&#34;&gt;dataset&lt;/a&gt; of ~3 million orders made by ~200,000 users at different days of week and times of day. There is also an ongoing &lt;a href=&#34;https://www.kaggle.com/c/instacart-market-basket-analysis&#34;&gt;Kaggle competition&lt;/a&gt; to predict which products a user will buy again. My goal here is more modest where I just wanted to explore the dataset to find patterns of purchasing behaviour by hour of day, day of week and number of days prior to current order. An &lt;a href=&#34;https://cdn-images-1.medium.com/max/800/1*wKfV6OV-_1Ipwrl7AjjSuw.png&#34;&gt;example&lt;/a&gt; of this kind of analysis is also shown in their blog. Here I wanted to explore if I can find such kind of patters by using the very common and popular dimension reduction technique - Principal Component Analysis (PCA). There are several great resources that introduce PCA if you are not familiar with PCA. One of the resources is the set of &lt;a href=&#34;https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/&#34;&gt;video lectures&lt;/a&gt; on machine learning by Prof. Hastie and Prof. Tibshirani.&lt;/p&gt;
&lt;p&gt;The general approach that I have followed is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do principal component analysis on the data (each row is a product, each column is a time period (hour of day, day of week or number of days prior to current order))&lt;/li&gt;
&lt;li&gt;Review the loading plots of first two principal components to see purchase patterns&lt;/li&gt;
&lt;li&gt;Identify top 20 products that have high scores in either first or the second principal component&lt;/li&gt;
&lt;li&gt;Check the purchasing pattern by checking the average number of orders for the products that were identified as having top scores in one of the principal components.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Spoiler Alert&lt;/strong&gt;: Since my analysis is basic, don’t be disappointed if there are no big Aha moments (there will be none). But I think it is still fun to see how we can extract such information directly from data.&lt;/p&gt;
&lt;p&gt;I downloaded the data from the following &lt;a href=&#34;https://www.instacart.com/datasets/grocery-shopping-2017&#34;&gt;link&lt;/a&gt;. The data dictionary is in the following &lt;a href=&#34;https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b&#34;&gt;link&lt;/a&gt;. The full code with results is in the following &lt;a href=&#34;http://notesofdabbler.github.io/blog_notesofdabbler/exploreData_PCA.html&#34;&gt;location&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Below are some basic info on the datasets&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The number of users are ~200,000.&lt;/li&gt;
&lt;li&gt;The number of orders are ~3.4M. The number of products are ~50K or which ~5K account for 80% of total orders&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;pca-to-find-patterns-of-purchase-by-hour-of-day&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;PCA to find patterns of purchase by hour of day&lt;/h2&gt;
&lt;p&gt;The goal here is to find products with different patterns of purchase timing by hour of day with PCA. Dataset for PCA has for each product (rows), the percentage of product orders at each hour of day (column). Since all the data is in percentages, I didn’t do any further scaling of data.&lt;/p&gt;
&lt;p&gt;The plot of cumulative variance shows that first component accounts for 44% of variance, first two account for 58% and first 3 account for 67% of variance.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/exploreInstacart/master/figure/unnamed-chunk-9-1.png&#34; width=&#34;600&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Next, we will look at the first two loadings since first 2 components account for 58% of variance.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/exploreInstacart/master/figure/unnamed-chunk-10-1.png&#34; width=&#34;600&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;First principal component loading PC1 indicates a pattern of either higher percentage of purcahses in the morning or evening. The second principal component loading indicates a pattern where there is higher purchase around 11am and 4pm. To check which product items follow these patterns, we look at products that either have high scores or low scores on a principal component. So here we take the top 20 and bottom 20 products in terms of their scores on PC1. The actual pattern still may not quite match the loading plot since the overall pattern is a combination of all principal component loadings.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/exploreInstacart/master/figure/unnamed-chunk-11-1.png&#34; width=&#34;600&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Below is the table that lists the actual products that are in top and bottom scores of PC1. Ice cream purchases tend to occur more in the evening. Items like granola bars, krispie treats, apples are purchased more in the morning.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/notesofdabbler/exploreInstacart/master/figure/top_bottom_20_products_PC1scores.png&#34; width=&#34;600&#34; /&gt;

&lt;/div&gt;
&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
&lt;script&gt;
(function() {
var d = document, s = d.createElement(&#39;script&#39;);
s.src = &#39;https://notesofdabbler.disqus.com/embed.js&#39;;
s.setAttribute(&#39;data-timestamp&#39;, +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;https://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>My First Blogdown Post</title>
      <link>/2017/05/15/myfirstblogdownpost/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/15/myfirstblogdownpost/</guid>
      <description>&lt;p&gt;Since I have been hearing a lot about virtues of &lt;a href=&#34;https://github.com/rstudio/blogdown&#34;&gt;Blogdown&lt;/a&gt; in various forums, I thought I will also give it a shot. I am planning to do my future blog posts in blogdown. I used to have my &lt;a href=&#34;http://notesofdabbler.wordpress.com&#34;&gt;older site&lt;/a&gt; in Wordpress. But I don’t have plans at least in the near term to migrate the older content.&lt;/p&gt;
&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
&lt;script&gt;
(function() {
var d = document, s = d.createElement(&#39;script&#39;);
s.src = &#39;https://notesofdabbler.disqus.com/embed.js&#39;;
s.setAttribute(&#39;data-timestamp&#39;, +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;https://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>&lt;p&gt;This blog is to catalog my learnings from others in topics related to R, Julia, Python, math, computations and visualizations. My older posts are in a &lt;a href=&#34;https://notesofdabbler.wordpress.com/&#34;&gt;blog&lt;/a&gt; in wordpress site. All views expressed here are my own and not representing anybody else (individual or company).&lt;/p&gt;

&lt;p&gt;Shankar Vaidyaraman&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Links</title>
      <link>/links/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/links/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.r-bloggers.com/&#34;&gt;R Bloggers&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>